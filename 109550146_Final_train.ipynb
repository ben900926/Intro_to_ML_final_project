{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "r-G0-NoGV_hu",
        "Wl_y4_LPs0jB"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ben900926/Intro_to_ML_final_project/blob/main/109550146_Final_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modules"
      ],
      "metadata": {
        "id": "wHk5crWqd73w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# download dependancy\n",
        "!pip install optuna\n",
        "!pip install category_encoders\n",
        "\n",
        "# download train, test data from my drive\n",
        "!gdown \"1GDmfpyUQJSR30OQGop1OfEPEos9sndrl\" # train.csv https://drive.google.com/file/d/1GDmfpyUQJSR30OQGop1OfEPEos9sndrl/view?usp=sharing\n",
        "!gdown \"1JBxfTEXZCGWfmKFQWUlEcwlBYVnIRcUh\" # test.csv https://drive.google.com/file/d/1JBxfTEXZCGWfmKFQWUlEcwlBYVnIRcUh/view?usp=sharing"
      ],
      "metadata": {
        "id": "5QLDOJqhqbL0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e3c8e00-4f10-4db8-ee26-a6b9bcf01b5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting optuna\n",
            "  Downloading optuna-3.0.5-py3-none-any.whl (348 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m348.5/348.5 KB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from optuna) (4.64.1)\n",
            "Collecting alembic>=1.5.0\n",
            "  Downloading alembic-1.9.1-py3-none-any.whl (210 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.4/210.4 KB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from optuna) (21.3)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.8/dist-packages (from optuna) (1.4.45)\n",
            "Collecting colorlog\n",
            "  Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.8/dist-packages (from optuna) (6.0)\n",
            "Collecting cliff\n",
            "  Downloading cliff-4.1.0-py3-none-any.whl (81 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.0/81.0 KB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting importlib-metadata<5.0.0\n",
            "  Downloading importlib_metadata-4.13.0-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from optuna) (1.21.6)\n",
            "Collecting cmaes>=0.8.2\n",
            "  Downloading cmaes-0.9.1-py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: scipy<1.9.0,>=1.7.0 in /usr/local/lib/python3.8/dist-packages (from optuna) (1.7.3)\n",
            "Collecting Mako\n",
            "  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 KB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: importlib-resources in /usr/local/lib/python3.8/dist-packages (from alembic>=1.5.0->optuna) (5.10.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata<5.0.0->optuna) (3.11.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->optuna) (3.0.9)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.8/dist-packages (from sqlalchemy>=1.3.0->optuna) (2.0.1)\n",
            "Requirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.8/dist-packages (from cliff->optuna) (3.5.0)\n",
            "Collecting autopage>=0.4.0\n",
            "  Downloading autopage-0.5.1-py3-none-any.whl (29 kB)\n",
            "Collecting stevedore>=2.0.1\n",
            "  Downloading stevedore-4.1.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.0/50.0 KB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cmd2>=1.0.0\n",
            "  Downloading cmd2-2.4.2-py3-none-any.whl (147 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.1/147.1 KB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyperclip>=1.6\n",
            "  Downloading pyperclip-1.8.2.tar.gz (20 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.8/dist-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n",
            "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.8/dist-packages (from cmd2>=1.0.0->cliff->optuna) (22.2.0)\n",
            "Collecting pbr!=2.1.0,>=2.0.0\n",
            "  Downloading pbr-5.11.0-py2.py3-none-any.whl (112 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.6/112.6 KB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.8/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.0.1)\n",
            "Building wheels for collected packages: pyperclip\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11136 sha256=011c543f2e9e79248c12b2763a78b86dd2e53ea8093ae45c8c26ddba1dc604e0\n",
            "  Stored in directory: /root/.cache/pip/wheels/7f/1a/65/84ff8c386bec21fca6d220ea1f5498a0367883a78dd5ba6122\n",
            "Successfully built pyperclip\n",
            "Installing collected packages: pyperclip, pbr, Mako, importlib-metadata, colorlog, cmd2, cmaes, autopage, stevedore, alembic, cliff, optuna\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib-metadata 5.2.0\n",
            "    Uninstalling importlib-metadata-5.2.0:\n",
            "      Successfully uninstalled importlib-metadata-5.2.0\n",
            "Successfully installed Mako-1.2.4 alembic-1.9.1 autopage-0.5.1 cliff-4.1.0 cmaes-0.9.1 cmd2-2.4.2 colorlog-6.7.0 importlib-metadata-4.13.0 optuna-3.0.5 pbr-5.11.0 pyperclip-1.8.2 stevedore-4.1.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting category_encoders\n",
            "  Downloading category_encoders-2.5.1.post0-py2.py3-none-any.whl (72 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.4/72.4 KB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.8/dist-packages (from category_encoders) (0.12.2)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from category_encoders) (1.7.3)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.8/dist-packages (from category_encoders) (1.21.6)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.8/dist-packages (from category_encoders) (1.0.2)\n",
            "Requirement already satisfied: pandas>=1.0.5 in /usr/local/lib/python3.8/dist-packages (from category_encoders) (1.3.5)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.8/dist-packages (from category_encoders) (0.5.3)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.0.5->category_encoders) (2022.7)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.0.5->category_encoders) (2.8.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from patsy>=0.5.1->category_encoders) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.20.0->category_encoders) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.20.0->category_encoders) (1.2.0)\n",
            "Installing collected packages: category_encoders\n",
            "Successfully installed category_encoders-2.5.1.post0\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1GDmfpyUQJSR30OQGop1OfEPEos9sndrl\n",
            "To: /content/train.csv\n",
            "100% 3.95M/3.95M [00:00<00:00, 167MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1JBxfTEXZCGWfmKFQWUlEcwlBYVnIRcUh\n",
            "To: /content/test.csv\n",
            "100% 3.06M/3.06M [00:00<00:00, 146MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cr5JcnDgw_x7",
        "outputId": "e7efd256-ba46-41e9-d427-0ca620dffc58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import random\n",
        "import numpy as np\n",
        "import itertools\n",
        "import time\n",
        "\n",
        "# model\n",
        "from sklearn.linear_model import LinearRegression, HuberRegressor, LogisticRegression\n",
        "from sklearn.impute import KNNImputer\n",
        "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
        "\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.base import clone\n",
        "# parameter search\n",
        "import optuna\n",
        "from optuna.pruners import PercentilePruner\n",
        "\n",
        "# Pipeline Constructors\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.compose import make_column_transformer\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "from category_encoders import WOEEncoder\n",
        "\n",
        "# save model\n",
        "import pickle"
      ],
      "metadata": {
        "id": "-N2BV1hRdA7U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hyperparameters\n",
        "SEED = 153\n",
        "NUM_TRIALS = 100\n",
        "\n",
        "################# You have to specify the path to store model weight! ##########\n",
        "MODEL_WEIGHT_PATH = \"drive/MyDrive/ml_final/model/final_model.pkl\"\n",
        "\n",
        "# enable parameter search or not (if enable, result might varies depending on which parameters optuna finds)\n",
        "PARA_SEARCH = False"
      ],
      "metadata": {
        "id": "qNBEB1E6xVBx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set seed\n",
        "def set_seeds(seed):\n",
        "  os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "  random.seed(seed)\n",
        "  tf.random.set_seed(seed)\n",
        "  np.random.seed(seed)"
      ],
      "metadata": {
        "id": "Rp8IRsHyfkDi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# training data"
      ],
      "metadata": {
        "id": "HQCe9SeHd_o2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv('train.csv')\n",
        "target = train_df.pop('failure')\n",
        "test_df = pd.read_csv('test.csv')\n",
        "\n",
        "# show content\n",
        "with pd.option_context(\"display.max_rows\", 10):\n",
        "  display(train_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "hSHluXlRd6eU",
        "outputId": "1c908b13-6f65-4787-bc48-e05e36b5affd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "          id product_code  loading attribute_0 attribute_1  attribute_2  \\\n",
              "0          0            A    80.10  material_7  material_8            9   \n",
              "1          1            A    84.89  material_7  material_8            9   \n",
              "2          2            A    82.43  material_7  material_8            9   \n",
              "3          3            A   101.07  material_7  material_8            9   \n",
              "4          4            A   188.06  material_7  material_8            9   \n",
              "...      ...          ...      ...         ...         ...          ...   \n",
              "26565  26565            E   158.95  material_7  material_6            6   \n",
              "26566  26566            E   146.02  material_7  material_6            6   \n",
              "26567  26567            E   115.62  material_7  material_6            6   \n",
              "26568  26568            E   106.38  material_7  material_6            6   \n",
              "26569  26569            E   131.20  material_7  material_6            6   \n",
              "\n",
              "       attribute_3  measurement_0  measurement_1  measurement_2  ...  \\\n",
              "0                5              7              8              4  ...   \n",
              "1                5             14              3              3  ...   \n",
              "2                5             12              1              5  ...   \n",
              "3                5             13              2              6  ...   \n",
              "4                5              9              2              8  ...   \n",
              "...            ...            ...            ...            ...  ...   \n",
              "26565            9              6             16              4  ...   \n",
              "26566            9             10             12              8  ...   \n",
              "26567            9              1             10              1  ...   \n",
              "26568            9              2              9              4  ...   \n",
              "26569            9              6             19              1  ...   \n",
              "\n",
              "       measurement_8  measurement_9  measurement_10  measurement_11  \\\n",
              "0             20.155         10.672          15.859          17.594   \n",
              "1             17.889         12.448          17.947          17.915   \n",
              "2             18.288         12.715          15.607             NaN   \n",
              "3             19.060         12.471          16.346          18.377   \n",
              "4             18.093         10.337          17.082          19.932   \n",
              "...              ...            ...             ...             ...   \n",
              "26565         19.354            NaN          12.177          17.942   \n",
              "26566         19.563         11.242          14.179          20.564   \n",
              "26567         19.279         11.407          16.437          17.476   \n",
              "26568         19.358         11.392          17.064          17.814   \n",
              "26569         18.731         10.611          15.603          19.703   \n",
              "\n",
              "       measurement_12  measurement_13  measurement_14  measurement_15  \\\n",
              "0              15.193          15.029             NaN          13.034   \n",
              "1              11.755          14.732          15.425          14.395   \n",
              "2              13.798          16.711          18.631          14.094   \n",
              "3              10.020          15.250          15.562          16.154   \n",
              "4              12.428          16.182          12.760          13.153   \n",
              "...               ...             ...             ...             ...   \n",
              "26565          10.112          15.795          18.572          16.144   \n",
              "26566          10.234          14.450          14.322          13.146   \n",
              "26567           8.668          15.069          16.599          15.590   \n",
              "26568          14.928          16.273          15.485          13.624   \n",
              "26569          11.006          15.875          13.366          16.527   \n",
              "\n",
              "       measurement_16  measurement_17  \n",
              "0              14.684         764.100  \n",
              "1              15.631         682.057  \n",
              "2              17.946         663.376  \n",
              "3              17.172         826.282  \n",
              "4              16.412         579.885  \n",
              "...               ...             ...  \n",
              "26565             NaN         729.131  \n",
              "26566          16.471         853.924  \n",
              "26567          14.065         750.364  \n",
              "26568          12.865         730.156  \n",
              "26569          17.890         602.354  \n",
              "\n",
              "[26570 rows x 25 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-73200156-6ccc-46ad-8514-57489783e21f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>product_code</th>\n",
              "      <th>loading</th>\n",
              "      <th>attribute_0</th>\n",
              "      <th>attribute_1</th>\n",
              "      <th>attribute_2</th>\n",
              "      <th>attribute_3</th>\n",
              "      <th>measurement_0</th>\n",
              "      <th>measurement_1</th>\n",
              "      <th>measurement_2</th>\n",
              "      <th>...</th>\n",
              "      <th>measurement_8</th>\n",
              "      <th>measurement_9</th>\n",
              "      <th>measurement_10</th>\n",
              "      <th>measurement_11</th>\n",
              "      <th>measurement_12</th>\n",
              "      <th>measurement_13</th>\n",
              "      <th>measurement_14</th>\n",
              "      <th>measurement_15</th>\n",
              "      <th>measurement_16</th>\n",
              "      <th>measurement_17</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>A</td>\n",
              "      <td>80.10</td>\n",
              "      <td>material_7</td>\n",
              "      <td>material_8</td>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "      <td>4</td>\n",
              "      <td>...</td>\n",
              "      <td>20.155</td>\n",
              "      <td>10.672</td>\n",
              "      <td>15.859</td>\n",
              "      <td>17.594</td>\n",
              "      <td>15.193</td>\n",
              "      <td>15.029</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13.034</td>\n",
              "      <td>14.684</td>\n",
              "      <td>764.100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>84.89</td>\n",
              "      <td>material_7</td>\n",
              "      <td>material_8</td>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "      <td>14</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>...</td>\n",
              "      <td>17.889</td>\n",
              "      <td>12.448</td>\n",
              "      <td>17.947</td>\n",
              "      <td>17.915</td>\n",
              "      <td>11.755</td>\n",
              "      <td>14.732</td>\n",
              "      <td>15.425</td>\n",
              "      <td>14.395</td>\n",
              "      <td>15.631</td>\n",
              "      <td>682.057</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>A</td>\n",
              "      <td>82.43</td>\n",
              "      <td>material_7</td>\n",
              "      <td>material_8</td>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>...</td>\n",
              "      <td>18.288</td>\n",
              "      <td>12.715</td>\n",
              "      <td>15.607</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13.798</td>\n",
              "      <td>16.711</td>\n",
              "      <td>18.631</td>\n",
              "      <td>14.094</td>\n",
              "      <td>17.946</td>\n",
              "      <td>663.376</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>A</td>\n",
              "      <td>101.07</td>\n",
              "      <td>material_7</td>\n",
              "      <td>material_8</td>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "      <td>13</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>...</td>\n",
              "      <td>19.060</td>\n",
              "      <td>12.471</td>\n",
              "      <td>16.346</td>\n",
              "      <td>18.377</td>\n",
              "      <td>10.020</td>\n",
              "      <td>15.250</td>\n",
              "      <td>15.562</td>\n",
              "      <td>16.154</td>\n",
              "      <td>17.172</td>\n",
              "      <td>826.282</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>A</td>\n",
              "      <td>188.06</td>\n",
              "      <td>material_7</td>\n",
              "      <td>material_8</td>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>...</td>\n",
              "      <td>18.093</td>\n",
              "      <td>10.337</td>\n",
              "      <td>17.082</td>\n",
              "      <td>19.932</td>\n",
              "      <td>12.428</td>\n",
              "      <td>16.182</td>\n",
              "      <td>12.760</td>\n",
              "      <td>13.153</td>\n",
              "      <td>16.412</td>\n",
              "      <td>579.885</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26565</th>\n",
              "      <td>26565</td>\n",
              "      <td>E</td>\n",
              "      <td>158.95</td>\n",
              "      <td>material_7</td>\n",
              "      <td>material_6</td>\n",
              "      <td>6</td>\n",
              "      <td>9</td>\n",
              "      <td>6</td>\n",
              "      <td>16</td>\n",
              "      <td>4</td>\n",
              "      <td>...</td>\n",
              "      <td>19.354</td>\n",
              "      <td>NaN</td>\n",
              "      <td>12.177</td>\n",
              "      <td>17.942</td>\n",
              "      <td>10.112</td>\n",
              "      <td>15.795</td>\n",
              "      <td>18.572</td>\n",
              "      <td>16.144</td>\n",
              "      <td>NaN</td>\n",
              "      <td>729.131</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26566</th>\n",
              "      <td>26566</td>\n",
              "      <td>E</td>\n",
              "      <td>146.02</td>\n",
              "      <td>material_7</td>\n",
              "      <td>material_6</td>\n",
              "      <td>6</td>\n",
              "      <td>9</td>\n",
              "      <td>10</td>\n",
              "      <td>12</td>\n",
              "      <td>8</td>\n",
              "      <td>...</td>\n",
              "      <td>19.563</td>\n",
              "      <td>11.242</td>\n",
              "      <td>14.179</td>\n",
              "      <td>20.564</td>\n",
              "      <td>10.234</td>\n",
              "      <td>14.450</td>\n",
              "      <td>14.322</td>\n",
              "      <td>13.146</td>\n",
              "      <td>16.471</td>\n",
              "      <td>853.924</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26567</th>\n",
              "      <td>26567</td>\n",
              "      <td>E</td>\n",
              "      <td>115.62</td>\n",
              "      <td>material_7</td>\n",
              "      <td>material_6</td>\n",
              "      <td>6</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>19.279</td>\n",
              "      <td>11.407</td>\n",
              "      <td>16.437</td>\n",
              "      <td>17.476</td>\n",
              "      <td>8.668</td>\n",
              "      <td>15.069</td>\n",
              "      <td>16.599</td>\n",
              "      <td>15.590</td>\n",
              "      <td>14.065</td>\n",
              "      <td>750.364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26568</th>\n",
              "      <td>26568</td>\n",
              "      <td>E</td>\n",
              "      <td>106.38</td>\n",
              "      <td>material_7</td>\n",
              "      <td>material_6</td>\n",
              "      <td>6</td>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>4</td>\n",
              "      <td>...</td>\n",
              "      <td>19.358</td>\n",
              "      <td>11.392</td>\n",
              "      <td>17.064</td>\n",
              "      <td>17.814</td>\n",
              "      <td>14.928</td>\n",
              "      <td>16.273</td>\n",
              "      <td>15.485</td>\n",
              "      <td>13.624</td>\n",
              "      <td>12.865</td>\n",
              "      <td>730.156</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26569</th>\n",
              "      <td>26569</td>\n",
              "      <td>E</td>\n",
              "      <td>131.20</td>\n",
              "      <td>material_7</td>\n",
              "      <td>material_6</td>\n",
              "      <td>6</td>\n",
              "      <td>9</td>\n",
              "      <td>6</td>\n",
              "      <td>19</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>18.731</td>\n",
              "      <td>10.611</td>\n",
              "      <td>15.603</td>\n",
              "      <td>19.703</td>\n",
              "      <td>11.006</td>\n",
              "      <td>15.875</td>\n",
              "      <td>13.366</td>\n",
              "      <td>16.527</td>\n",
              "      <td>17.890</td>\n",
              "      <td>602.354</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>26570 rows × 25 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-73200156-6ccc-46ad-8514-57489783e21f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-73200156-6ccc-46ad-8514-57489783e21f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-73200156-6ccc-46ad-8514-57489783e21f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Correlation with attribute 3~9 and measurement 17"
      ],
      "metadata": {
        "id": "V85Yg7lAD8U1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocessing(df_train, df_test):\n",
        "    data = pd.concat([df_train, df_test])\n",
        "    \n",
        "    # new attribute inspired by disscusion\n",
        "    data['area'] = data['attribute_2'] * data['attribute_3']\n",
        "    data['m3_null'] = data['measurement_3'].isnull().astype(np.int64)\n",
        "    data['m5_null'] = data['measurement_5'].isnull().astype(np.int64)\n",
        "    feature = [f for f in df_test.columns if f.startswith('measurement') or f =='loading']\n",
        "\n",
        "    # measurement 17\n",
        "    full_fill_dict ={}\n",
        "    full_fill_dict['measurement_17'] = {\n",
        "        'A': [                'measurement_4','measurement_5','measurement_6','measurement_7','measurement_8'],\n",
        "        'B': ['measurement_3','measurement_4','measurement_5',                'measurement_7',                'measurement_9'],\n",
        "        'C': [                                'measurement_5','measurement_6','measurement_7','measurement_8','measurement_9'],\n",
        "        'D': ['measurement_3',                'measurement_5','measurement_6','measurement_7','measurement_8'],\n",
        "        'E': [                'measurement_4','measurement_5','measurement_6',                'measurement_8','measurement_9'],\n",
        "        'F': [                'measurement_4','measurement_5','measurement_6','measurement_7'],\n",
        "        'G': [                'measurement_4','measurement_5','measurement_6',                'measurement_8','measurement_9'],\n",
        "        'H': [                'measurement_4','measurement_5',                'measurement_7','measurement_8','measurement_9'],\n",
        "        'I': ['measurement_3','measurement_4',                'measurement_7','measurement_8','measurement_9']\n",
        "    }\n",
        "\n",
        "    # features without measurement\n",
        "    col = [col for col in df_test.columns if 'measurement' not in col]+ ['loading', 'm3_null', 'm5_null']\n",
        "    a = []\n",
        "    b = []\n",
        "\n",
        "    for x in range(3,17):\n",
        "      # correlation between each measurement and measurement 3~17\n",
        "      corr = np.absolute(data.drop(col, axis=1).corr()[f'measurement_{x}']).sort_values(ascending=False)\n",
        "      # sorted\n",
        "      corr = corr.sort_values(ascending=False)\n",
        "      a.append(np.round(np.sum(corr[1:4]),3))\n",
        "      b.append(f'measurement_{x}')\n",
        "\n",
        "    # making df with correlations\n",
        "    corr_df = pd.DataFrame()\n",
        "    corr_df['corr_sum'] = b\n",
        "    corr_df['selected_col'] = a\n",
        "    corr_df = corr_df.sort_values(by = 'corr_sum',ascending=False).reset_index(drop=True)\n",
        "\n",
        "    # select top-10 measurement with highest correlation\n",
        "    for i in range(10):\n",
        "      measurement_col = 'measurement_' + corr_df.iloc[i,0][12:]\n",
        "      fill_dict = {}\n",
        "      # correlation for each production code\n",
        "      for x in data.product_code.unique() : \n",
        "          #print(measurement_col)\n",
        "          corr = np.absolute(data[data.product_code == x].drop(col, axis=1).corr()[measurement_col]).sort_values(ascending=False)\n",
        "          # {'measurement_8': ['measurement_17', 'measurement_2', 'measurement_0', 'measurement_3']}\n",
        "          measurement_col_dic = {}\n",
        "          measurement_col_dic[measurement_col] = corr[1:5].index.tolist()\n",
        "          fill_dict[x] = measurement_col_dic[measurement_col]\n",
        "      full_fill_dict[measurement_col] =fill_dict\n",
        "\n",
        "    feature = [f for f in data.columns if f.startswith('measurement') or f=='loading']\n",
        "    nullValue_cols = [col for col in df_train.columns if df_train[col].isnull().sum()!=0]\n",
        "\n",
        "    for code in data.product_code.unique():\n",
        "      # we are using high-correlated given measurements to predict missing measurement_col\n",
        "      for measurement_col in list(full_fill_dict.keys()):\n",
        "        # train model with non-null\n",
        "        tmp = data[data.product_code == code]\n",
        "        column = full_fill_dict[measurement_col][code]\n",
        "        tmp_train = tmp[column+[measurement_col]].dropna(how='any')\n",
        "        measurement_null = (tmp[column].isnull().sum(axis=1) == 0) & (tmp[measurement_col].isnull())\n",
        "        tmp_test = tmp[measurement_null]\n",
        "\n",
        "        # using HugerRegressor(linear regression that is robust to outlines) to predict missing value\n",
        "        model = HuberRegressor(epsilon=1.9, max_iter=500)\n",
        "        model.fit(tmp_train[column], tmp_train[measurement_col])\n",
        "        measure_null_only = (data.product_code==code) & (data[column].isnull().sum(axis=1)==0) & (data[measurement_col].isnull())\n",
        "        data.loc[measure_null_only, measurement_col] = model.predict(tmp_test[column])\n",
        "\n",
        "      # now using KNN imputer to impute missing values\n",
        "      model1 = KNNImputer(n_neighbors=3)\n",
        "      data.loc[data.product_code==code, feature] = model1.fit_transform(data.loc[data.product_code==code, feature])\n",
        "\n",
        "    # average of measurement\n",
        "    data['measurement_avg'] = data[[f'measurement_{i}' for i in range(3, 17)]].mean(axis=1)\n",
        "    df_train = data.iloc[:df_train.shape[0],:]\n",
        "    df_test = data.iloc[df_train.shape[0]:,:]\n",
        "    features = ['loading', 'attribute_0', 'measurement_17', 'measurement_0', 'measurement_1', 'measurement_2', 'area', 'm3_null', 'm5_null', 'measurement_avg']\n",
        "    \n",
        "    return df_train, df_test, features"
      ],
      "metadata": {
        "id": "gflBoxjUTzVF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cross Validation"
      ],
      "metadata": {
        "id": "ByxG5hftGS2d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# use 2 production groups for valid set\n",
        "production = train_df[\"product_code\"].unique()\n",
        "# pick 2 index out of five product codes\n",
        "cmb_groups = list(itertools.combinations(production, 2))\n",
        "\n",
        "train_index = []\n",
        "valid_index = []\n",
        "\n",
        "# pick out data using these codes\n",
        "for group in cmb_groups:\n",
        "  group_zero_list = train_df.loc[train_df[\"product_code\"]==group[0], :].index\n",
        "  group_one_list = train_df.loc[train_df[\"product_code\"]==group[1], :].index\n",
        "  # combine two list\n",
        "  list0 = list(group_zero_list)\n",
        "  list1 = list(group_one_list)\n",
        "  tmp_list = list0 + list1\n",
        "\n",
        "  # total list - test set = train set\n",
        "  train_set = set(list(train_df.index)) - set(tmp_list)\n",
        "  train_index.append(list(train_set))\n",
        "  valid_index.append(tmp_list)\n"
      ],
      "metadata": {
        "id": "TOxQw9v0GV-9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Model"
      ],
      "metadata": {
        "id": "p_s2xuMMF3fb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocess\n",
        "train = train_df.copy()\n",
        "test = test_df.copy()\n",
        "x_train, x_test, features = preprocessing(train, test)"
      ],
      "metadata": {
        "id": "UjTxDvD_1zdd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pipeline (to make preprocessing faster)\n",
        "preprocessing_pp = make_pipeline(\n",
        "    make_column_transformer(\n",
        "        (WOEEncoder(), ['attribute_0']), # turn string into binary value\n",
        "        (FunctionTransformer(np.log1p), ['loading']),\n",
        "        remainder = 'passthrough'\n",
        "    ),\n",
        "    RobustScaler()\n",
        ")"
      ],
      "metadata": {
        "id": "XWu418dV8R-L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "######################### cross validation #######################\n",
        "\n",
        "# main train loop here\n",
        "def score(input_model):\n",
        "  set_seeds(seed=SEED)\n",
        "\n",
        "  # store some results\n",
        "  test_preds = np.zeros((x_test.shape[0],)) \n",
        "  train_preds = np.zeros((x_train.shape[0],))\n",
        "  scores = np.zeros(len(train_index))\n",
        "  total_time = 0\n",
        "\n",
        "  start = time.time()\n",
        "  for fold, train_ in enumerate(train_index):\n",
        "    # training data\n",
        "    x_train_ = x_train[features].iloc[train_, :].copy()\n",
        "    y_train = target[train_].copy()\n",
        "    valid_indices_in_df = valid_index[fold]\n",
        "    x_valid_ = x_train[features].iloc[valid_indices_in_df, :].copy()\n",
        "    y_valid = target[valid_indices_in_df].copy()\n",
        "\n",
        "    # define model and train\n",
        "    model = make_pipeline(\n",
        "        clone(preprocessing_pp),\n",
        "        clone(input_model)\n",
        "    )\n",
        "\n",
        "    model.fit(x_train_, y_train)\n",
        "    # get predictions\n",
        "    valid_pred = model.predict_proba(x_valid_)[:,1]\n",
        "    test_preds += model.predict_proba(x_test)[:,1] / len(train_index)\n",
        "    train_preds[valid_indices_in_df] = valid_pred\n",
        "    scores[fold] = roc_auc_score(y_valid, valid_pred)\n",
        "    end = time.time()\n",
        "    total_time += (end-start)\n",
        "  \n",
        "  print(f'Worst: {round(np.min(scores), 6)}')\n",
        "  print(f'Average:{round(np.mean(scores), 6)}')\n",
        "  print(f'Process time: ', total_time)\n",
        "\n",
        "  return np.mean(scores), test_preds"
      ],
      "metadata": {
        "id": "cwg9zw58TPdr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Parameter Search"
      ],
      "metadata": {
        "id": "UBShvQnyocam"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# general parameters used for t\n",
        "default_params = dict(            \n",
        "    solver = 'liblinear', # nice solver for small dataset\n",
        "    penalty = 'l1', # xgboost, l1, l2. This one suits the most\n",
        "    max_iter = 500,\n",
        "    random_state = SEED,\n",
        ")\n",
        "\n",
        "# keep specified percentage of prune\n",
        "pruner = PercentilePruner(\n",
        "    percentile = 75,\n",
        "    n_startup_trials = 15,\n",
        "    n_warmup_steps = 5,\n",
        "    n_min_trials = 15,\n",
        ")\n",
        "\n",
        "def parameter_search(trials):\n",
        "    \n",
        "    # Optuna objective function\n",
        "    def objective(trial):\n",
        "        model_params = dict( \n",
        "            # default 1.0\n",
        "            C = trial.suggest_float(\n",
        "                \"C\", 1e-10, 100\n",
        "            ),\n",
        "        )\n",
        "        model = LogisticRegression(\n",
        "            **default_params,\n",
        "            **model_params\n",
        "        )\n",
        "        return score(model)[0]\n",
        "    \n",
        "    \n",
        "    optuna.logging.set_verbosity(optuna.logging.DEBUG)\n",
        "    study = optuna.create_study(pruner = pruner,direction = \"maximize\")\n",
        "    # Close to defaults\n",
        "    study.enqueue_trial({'C': 1.0})\n",
        "    study.optimize(objective, n_trials=trials)\n",
        "    return study\n",
        "\n",
        "# do parameter search only if specified\n",
        "params = {}\n",
        "if PARA_SEARCH:\n",
        "  study = parameter_search(NUM_TRIALS)\n",
        "  params = study.best_params\n",
        "else:\n",
        "  # the one I trained\n",
        "  params = {'C': 0.1635393159306732}"
      ],
      "metadata": {
        "id": "V2sePTfnoHQI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save model weight"
      ],
      "metadata": {
        "id": "VeGGyfXrb2jd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = LogisticRegression(**default_params, **params) \n",
        "# save model\n",
        "pkl_filename = MODEL_WEIGHT_PATH\n",
        "with open(pkl_filename, 'wb') as pklFile:\n",
        "  pickle.dump(model, pklFile)"
      ],
      "metadata": {
        "id": "ShzrwETYiKhd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}